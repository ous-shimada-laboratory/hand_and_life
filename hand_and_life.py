import cv2
import numpy as np
import time
import os
import json
from datetime import datetime

# MediaPipeã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’try-catchã§å›²ã‚€
try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    print("Warning: MediaPipeãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚åŸºæœ¬çš„ãªè‚Œè‰²æ¤œå‡ºã®ã¿ä½¿ç”¨ã—ã¾ã™ã€‚")
    print("pip install mediapipe ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚")

# ===== æ”¹è‰¯ã•ã‚ŒãŸæ‰‹ã¨æŒ‡ã®æ¤œå‡ºãƒ»åˆ†æã‚¯ãƒ©ã‚¹ =====
class AdvancedHandTracker:
    def __init__(self):
        if not MEDIAPIPE_AVAILABLE:
            self.hands = None
            return
            
        # MediaPipeåˆæœŸåŒ–
        self.mp_hands = mp.solutions.hands
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        # è¨˜äº‹ã‚’å‚è€ƒã«ã—ãŸè©³ç´°è¨­å®š
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.7,  # è¨˜äº‹ã‚ˆã‚Šå°‘ã—é«˜ã‚ã«è¨­å®š
            min_tracking_confidence=0.5    # è¨˜äº‹ã¨åŒã˜å€¤
        )
        
        # 21å€‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®åå‰ãƒªã‚¹ãƒˆï¼ˆè¨˜äº‹ã‚ˆã‚Šï¼‰
        self.landmark_names = [
            'WRIST', 'THUMB_CMC', 'THUMB_MCP', 'THUMB_IP', 'THUMB_TIP',
            'INDEX_FINGER_MCP', 'INDEX_FINGER_PIP', 'INDEX_FINGER_DIP', 'INDEX_FINGER_TIP',
            'MIDDLE_FINGER_MCP', 'MIDDLE_FINGER_PIP', 'MIDDLE_FINGER_DIP', 'MIDDLE_FINGER_TIP',
            'RING_FINGER_MCP', 'RING_FINGER_PIP', 'RING_FINGER_DIP', 'RING_FINGER_TIP',
            'PINKY_MCP', 'PINKY_PIP', 'PINKY_DIP', 'PINKY_TIP'
        ]
        
        # æŒ‡å…ˆã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ID
        self.fingertip_ids = [4, 8, 12, 16, 20]  # THUMB_TIP, INDEX_TIP, MIDDLE_TIP, RING_TIP, PINKY_TIP
        
        # æŒ‡ã®é–¢ç¯€IDï¼ˆå„æŒ‡ã®éª¨æ ¼ï¼‰
        self.finger_joints = {
            'thumb': [1, 2, 3, 4],      # CMC, MCP, IP, TIP
            'index': [5, 6, 7, 8],      # MCP, PIP, DIP, TIP
            'middle': [9, 10, 11, 12],  # MCP, PIP, DIP, TIP
            'ring': [13, 14, 15, 16],   # MCP, PIP, DIP, TIP
            'pinky': [17, 18, 19, 20]   # MCP, PIP, DIP, TIP
        }
        
        # æ‰‹ã®ã²ã‚‰ã®æ¥ç¶šï¼ˆè¨˜äº‹ã‚’å‚è€ƒã«è©³ç´°åŒ–ï¼‰
        self.palm_connections = [(0, 1), (0, 5), (5, 9), (9, 13), (13, 17), (0, 17)]
        
        # æŒ‡ã”ã¨ã®è‰²ï¼ˆã‚ˆã‚Šé®®ã‚„ã‹ã«ï¼‰
        self.finger_colors = {
            'thumb': (255, 100, 100),    # æ˜ã‚‹ã„èµ¤
            'index': (100, 255, 100),    # æ˜ã‚‹ã„ç·‘
            'middle': (100, 100, 255),   # æ˜ã‚‹ã„é’
            'ring': (255, 255, 100),     # æ˜ã‚‹ã„é»„
            'pinky': (255, 100, 255),    # æ˜ã‚‹ã„ãƒã‚¼ãƒ³ã‚¿
            'palm': (255, 255, 255)      # ç™½
        }
        
        # æ¤œå‡ºçµ±è¨ˆç”¨
        self.detection_stats = {
            'total_frames': 0,
            'hands_detected': 0,
            'left_hands': 0,
            'right_hands': 0,
            'confidence_scores': []
        }
    
    def detect_hands(self, image):
        """æ‰‹ã®æ¤œå‡ºã‚’å®Ÿè¡Œã—ã€è©³ç´°ãªçµæœã‚’è¿”ã™"""
        if not MEDIAPIPE_AVAILABLE or self.hands is None:
            return None
            
        # è¨˜äº‹ã¨åŒã˜è‰²å¤‰æ›å‡¦ç†
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.hands.process(rgb_image)
        
        # çµ±è¨ˆæ›´æ–°
        self.detection_stats['total_frames'] += 1
        if results.multi_hand_landmarks:
            self.detection_stats['hands_detected'] += len(results.multi_hand_landmarks)
            
            # å·¦å³ã®æ‰‹ã®çµ±è¨ˆ
            if results.multi_handedness:
                for handedness in results.multi_handedness:
                    if handedness.classification[0].label == 'Left':
                        self.detection_stats['left_hands'] += 1
                    else:
                        self.detection_stats['right_hands'] += 1
                    
                    # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨˜éŒ²
                    confidence = handedness.classification[0].score
                    self.detection_stats['confidence_scores'].append(confidence)
        
        return results
    
    def analyze_hand_landmarks(self, hand_landmarks, handedness_info=None):
        """æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’è©³ç´°åˆ†æï¼ˆè¨˜äº‹ã®åˆ†ææ‰‹æ³•ã‚’å‚è€ƒï¼‰"""
        analysis = {
            'landmark_coords': [],
            'fingertip_coords': [],
            'hand_label': 'Unknown',
            'confidence': 0.0,
            'finger_angles': {},
            'hand_size': 0.0,
            'palm_center': (0, 0)
        }
        
        # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ã‚’å–å¾—
        for i, landmark in enumerate(hand_landmarks.landmark):
            coord_info = {
                'id': i,
                'name': self.landmark_names[i],
                'x': landmark.x,
                'y': landmark.y,
                'z': landmark.z
            }
            analysis['landmark_coords'].append(coord_info)
        
        # æŒ‡å…ˆåº§æ¨™ã‚’ç‰¹åˆ¥ã«å–å¾—
        for tip_id in self.fingertip_ids:
            tip = hand_landmarks.landmark[tip_id]
            analysis['fingertip_coords'].append({
                'finger': self.landmark_names[tip_id],
                'x': tip.x,
                'y': tip.y,
                'z': tip.z
            })
        
        # å·¦å³åˆ¤å®šæƒ…å ±
        if handedness_info:
            analysis['hand_label'] = handedness_info.classification[0].label
            analysis['confidence'] = handedness_info.classification[0].score
        
        # æ‰‹ã®ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆæ‰‹é¦–ã‹ã‚‰ä¸­æŒ‡å…ˆç«¯ã¾ã§ã®è·é›¢ï¼‰
        wrist = hand_landmarks.landmark[0]
        middle_tip = hand_landmarks.landmark[12]
        analysis['hand_size'] = np.sqrt(
            (middle_tip.x - wrist.x)**2 + 
            (middle_tip.y - wrist.y)**2
        )
        
        # æ‰‹ã®ã²ã‚‰ä¸­å¿ƒè¨ˆç®—
        palm_landmarks = [0, 5, 9, 13, 17]  # æ‰‹é¦–ã¨å„æŒ‡ã®ä»˜ã‘æ ¹
        palm_x = sum(hand_landmarks.landmark[i].x for i in palm_landmarks) / len(palm_landmarks)
        palm_y = sum(hand_landmarks.landmark[i].y for i in palm_landmarks) / len(palm_landmarks)
        analysis['palm_center'] = (palm_x, palm_y)
        
        return analysis
    
    def draw_detailed_hand_skeleton(self, image, hand_landmarks, handedness_info=None):
        """è¨˜äº‹ã‚’å‚è€ƒã«ã—ãŸè©³ç´°ãªæ‰‹ã®éª¨æ ¼æç”»"""
        if not MEDIAPIPE_AVAILABLE:
            return [], {}
            
        h, w, _ = image.shape
        
        # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ç”»åƒåº§æ¨™ã«å¤‰æ›
        landmarks = []
        for lm in hand_landmarks.landmark:
            x = int(lm.x * w)
            y = int(lm.y * h)
            landmarks.append((x, y))
        
        # æ‰‹ã®è©³ç´°åˆ†æ
        analysis = self.analyze_hand_landmarks(hand_landmarks, handedness_info)
        
        # æŒ‡ã”ã¨ã«éª¨æ ¼ã‚’æç”»ï¼ˆè¨˜äº‹ã®æç”»æ–¹æ³•ã‚’æ”¹è‰¯ï¼‰
        for finger_name, joints in self.finger_joints.items():
            color = self.finger_colors[finger_name]
            
            # æŒ‡ã®éª¨æ ¼ã‚’ç·šã§ç¹‹ãï¼ˆå¤ªã•ã‚’é–¢ç¯€ã”ã¨ã«å¤‰åŒ–ï¼‰
            for i in range(len(joints) - 1):
                start_point = landmarks[joints[i]]
                end_point = landmarks[joints[i + 1]]
                
                # é–¢ç¯€ã®é‡è¦åº¦ã«å¿œã˜ã¦å¤ªã•ã‚’å¤‰æ›´
                thickness = 5 if i == 0 else 4 if i == 1 else 3
                cv2.line(image, start_point, end_point, color, thickness)
                
                # é–¢ç¯€ç‚¹ã‚’å††ã§æç”»ï¼ˆã‚µã‚¤ã‚ºã‚‚å¤‰åŒ–ï¼‰
                radius = 7 if i == 0 else 6 if i == 1 else 5
                cv2.circle(image, start_point, radius, color, -1)
                cv2.circle(image, end_point, radius, color, -1)
        
        # æ‰‹ã®ã²ã‚‰ã®æ¥ç¶šã‚’æç”»
        palm_color = self.finger_colors['palm']
        for connection in self.palm_connections:
            start_point = landmarks[connection[0]]
            end_point = landmarks[connection[1]]
            cv2.line(image, start_point, end_point, palm_color, 3)
        
        # æŒ‡å…ˆã‚’ç‰¹åˆ¥ã«å¼·èª¿ï¼ˆè¨˜äº‹ã‚ˆã‚Šè©³ç´°åŒ–ï¼‰
        for i, tip_id in enumerate(self.fingertip_ids):
            tip_point = landmarks[tip_id]
            finger_name = list(self.finger_joints.keys())[i]
            finger_color = self.finger_colors[finger_name]
            
            # ä¸‰é‡å††ã§å¼·èª¿
            cv2.circle(image, tip_point, 15, (0, 255, 255), -1)    # æœ€å¤– - é»„è‰²
            cv2.circle(image, tip_point, 12, finger_color, -1)      # ä¸­é–“ - æŒ‡è‰²
            cv2.circle(image, tip_point, 8, (255, 255, 255), -1)    # å†…å´ - ç™½
            cv2.circle(image, tip_point, 18, (0, 0, 0), 2)          # é»’ã„å¤–æ 
        
        # æ‰‹ã®ãƒ©ãƒ™ãƒ«ã¨ä¿¡é ¼åº¦ã‚’æç”»
        if handedness_info:
            label = handedness_info.classification[0].label
            confidence = handedness_info.classification[0].score
            
            # æ‰‹é¦–ä»˜è¿‘ã«ãƒ©ãƒ™ãƒ«è¡¨ç¤º
            wrist_point = landmarks[0]
            label_pos = (wrist_point[0] - 50, wrist_point[1] - 30)
            
            cv2.putText(image, f"{label} Hand", label_pos, 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(image, f"Conf: {confidence:.3f}", 
                       (label_pos[0], label_pos[1] + 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 2)
        
        return landmarks, analysis
    
    def draw_advanced_fingertip_connections(self, image, landmarks_list, analysis_list):
        """è¤‡æ•°ã®æ‰‹ã®æŒ‡å…ˆã‚’é«˜åº¦ã«æ¥ç¶šã™ã‚‹æç”»"""
        if len(landmarks_list) == 0:
            return
        
        # å˜ä¸€ã®æ‰‹ã®å ´åˆ
        if len(landmarks_list) == 1:
            landmarks = landmarks_list[0]
            self._draw_single_hand_connections(image, landmarks)
        
        # è¤‡æ•°ã®æ‰‹ã®å ´åˆï¼ˆè¨˜äº‹ã§ã¯æœ€å¤§2ã¤ã¾ã§æ¤œå‡ºï¼‰
        elif len(landmarks_list) == 2:
            self._draw_multi_hand_connections(image, landmarks_list, analysis_list)
    
    def _draw_single_hand_connections(self, image, landmarks):
        """å˜ä¸€ã®æ‰‹ã®æŒ‡å…ˆæ¥ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³"""
        fingertips = [landmarks[i] for i in self.fingertip_ids]
        
        # åŸºæœ¬çš„ãªå¤šè§’å½¢æ¥ç¶š
        for i in range(len(fingertips)):
            start_point = fingertips[i]
            end_point = fingertips[(i + 1) % len(fingertips)]
            cv2.line(image, start_point, end_point, (255, 255, 0), 3)
        
        # æ˜Ÿå‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¸­å¿ƒã‹ã‚‰æ”¾å°„ï¼‰
        if len(fingertips) >= 3:
            center_x = sum(p[0] for p in fingertips) // len(fingertips)
            center_y = sum(p[1] for p in fingertips) // len(fingertips)
            center_point = (center_x, center_y)
            
            for i, tip in enumerate(fingertips):
                color = list(self.finger_colors.values())[i]
                cv2.line(image, center_point, tip, color, 2)
            
            cv2.circle(image, center_point, 10, (0, 255, 255), -1)
    
    def _draw_multi_hand_connections(self, image, landmarks_list, analysis_list):
        """è¤‡æ•°ã®æ‰‹ã®é–“ã®æ¥ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³"""
        # å„æ‰‹ã®æŒ‡å…ˆã‚’å–å¾—
        all_fingertips = []
        hand_centers = []
        
        for landmarks, analysis in zip(landmarks_list, analysis_list):
            fingertips = [landmarks[i] for i in self.fingertip_ids]
            all_fingertips.extend(fingertips)
            
            # æ‰‹ã®ä¸­å¿ƒã‚‚è¨ˆç®—
            center_x = sum(p[0] for p in fingertips) // len(fingertips)
            center_y = sum(p[1] for p in fingertips) // len(fingertips)
            hand_centers.append((center_x, center_y))
        
        # å·¦å³ã®æ‰‹ã®ä¸­å¿ƒã‚’æ¥ç¶š
        if len(hand_centers) == 2:
            cv2.line(image, hand_centers[0], hand_centers[1], (255, 0, 255), 4)
            
            # ä¸­ç‚¹ã‚‚æç”»
            mid_x = (hand_centers[0][0] + hand_centers[1][0]) // 2
            mid_y = (hand_centers[0][1] + hand_centers[1][1]) // 2
            cv2.circle(image, (mid_x, mid_y), 8, (255, 0, 255), -1)
        
        # å¯¾å¿œã™ã‚‹æŒ‡å…ˆåŒå£«ã‚’æ¥ç¶šï¼ˆè¦ªæŒ‡åŒå£«ã€äººå·®ã—æŒ‡åŒå£«ãªã©ï¼‰
        if len(landmarks_list) == 2:
            for i in range(len(self.fingertip_ids)):
                tip1 = landmarks_list[0][self.fingertip_ids[i]]
                tip2 = landmarks_list[1][self.fingertip_ids[i]]
                color = list(self.finger_colors.values())[i]
                cv2.line(image, tip1, tip2, color, 2, cv2.LINE_AA)
    
    def save_detection_data(self, landmarks_list, analysis_list, frame_number):
        """æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’è¨˜äº‹ã®ã‚ˆã†ãªå½¢å¼ã§ä¿å­˜"""
        detection_data = {
            'frame_number': frame_number,
            'timestamp': datetime.now().isoformat(),
            'hands_count': len(landmarks_list),
            'hands_data': []
        }
        
        for i, (landmarks, analysis) in enumerate(zip(landmarks_list, analysis_list)):
            hand_data = {
                'hand_id': i,
                'hand_label': analysis['hand_label'],
                'confidence': analysis['confidence'],
                'hand_size': analysis['hand_size'],
                'palm_center': analysis['palm_center'],
                'landmarks': []
            }
            
            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æƒ…å ±ã‚’ä¿å­˜
            for coord_info in analysis['landmark_coords']:
                hand_data['landmarks'].append(coord_info)
            
            detection_data['hands_data'].append(hand_data)
        
        return detection_data
    
    def get_detection_statistics(self):
        """æ¤œå‡ºçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if self.detection_stats['total_frames'] == 0:
            return {}
        
        avg_confidence = 0
        if self.detection_stats['confidence_scores']:
            avg_confidence = sum(self.detection_stats['confidence_scores']) / len(self.detection_stats['confidence_scores'])
        
        detection_rate = (self.detection_stats['hands_detected'] / self.detection_stats['total_frames']) * 100
        
        return {
            'total_frames': self.detection_stats['total_frames'],
            'hands_detected': self.detection_stats['hands_detected'],
            'left_hands': self.detection_stats['left_hands'],
            'right_hands': self.detection_stats['right_hands'],
            'detection_rate': detection_rate,
            'average_confidence': avg_confidence,
            'confidence_scores': self.detection_stats['confidence_scores'][-10:]  # æœ€æ–°10å€‹
        }

# ===== æ”¹è‰¯ã•ã‚ŒãŸè‚Œè‰²æ¤œå‡ºï¼ˆè¨˜äº‹ã®æ‰‹æ³•ã¨çµ„ã¿åˆã‚ã›ï¼‰=====
def enhanced_skin_mask_with_analysis(img, hand_tracker):
    """è¨˜äº‹ã®åˆ†æçµæœã‚‚å«ã‚ãŸæ”¹è‰¯ç‰ˆè‚Œè‰²æ¤œå‡º"""
    # å¾“æ¥ã®è‚Œè‰²æ¤œå‡ºï¼ˆè¤‡æ•°ã®è‰²ç©ºé–“ï¼‰
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    # HSVã§ã®è‚Œè‰²ç¯„å›²ï¼ˆè¨˜äº‹ã‚’å‚è€ƒã«æœ€é©åŒ–ï¼‰
    lower1 = np.array([0, 30, 60], dtype=np.uint8)
    upper1 = np.array([20, 150, 255], dtype=np.uint8)
    mask1 = cv2.inRange(hsv, lower1, upper1)
    
    lower2 = np.array([160, 30, 60], dtype=np.uint8)
    upper2 = np.array([180, 150, 255], dtype=np.uint8)
    mask2 = cv2.inRange(hsv, lower2, upper2)
    
    # YCrCbã§ã®è‚Œè‰²æ¤œå‡º
    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)
    lower_ycrcb = np.array([0, 135, 85], dtype=np.uint8)
    upper_ycrcb = np.array([255, 180, 135], dtype=np.uint8)
    mask3 = cv2.inRange(ycrcb, lower_ycrcb, upper_ycrcb)
    
    # åŸºæœ¬ã®è‚Œè‰²ãƒã‚¹ã‚¯
    skin_mask = cv2.bitwise_or(mask1, mask2)
    skin_mask = cv2.bitwise_or(skin_mask, mask3)
    
    # é«˜ç²¾åº¦æ‰‹èªè­˜çµæœ
    hand_mask = np.zeros(img.shape[:2], dtype=np.uint8)
    landmarks_list = []
    analysis_list = []
    detection_info = {
        'hands_detected': 0,
        'left_hands': 0,
        'right_hands': 0,
        'total_confidence': 0,
        'hand_analyses': []
    }
    
    if MEDIAPIPE_AVAILABLE and hand_tracker.hands is not None:
        results = hand_tracker.detect_hands(img)
        
        if results.multi_hand_landmarks:
            detection_info['hands_detected'] = len(results.multi_hand_landmarks)
            
            for i, hand_landmarks in enumerate(results.multi_hand_landmarks):
                # å·¦å³åˆ¤å®šæƒ…å ±ã‚’å–å¾—
                handedness_info = None
                if results.multi_handedness and i < len(results.multi_handedness):
                    handedness_info = results.multi_handedness[i]
                    label = handedness_info.classification[0].label
                    confidence = handedness_info.classification[0].score
                    
                    if label == 'Left':
                        detection_info['left_hands'] += 1
                    else:
                        detection_info['right_hands'] += 1
                    
                    detection_info['total_confidence'] += confidence
                
                # è©³ç´°ãªæ‰‹ã®éª¨æ ¼ã‚’æç”»
                landmarks, analysis = hand_tracker.draw_detailed_hand_skeleton(
                    img, hand_landmarks, handedness_info
                )
                
                landmarks_list.append(landmarks)
                analysis_list.append(analysis)
                detection_info['hand_analyses'].append(analysis)
                
                # ã‚ˆã‚Šæ­£ç¢ºãªæ‰‹ã®å½¢çŠ¶ãƒã‚¹ã‚¯ã‚’ä½œæˆ
                individual_mask = create_precise_hand_mask(img, hand_landmarks)
                hand_mask = cv2.bitwise_or(hand_mask, individual_mask)
        
        # é«˜åº¦ãªæŒ‡å…ˆæ¥ç¶šã‚’æç”»
        if landmarks_list:
            hand_tracker.draw_advanced_fingertip_connections(img, landmarks_list, analysis_list)
    
    # ãƒã‚¹ã‚¯ã®çµåˆã¨æœ€é©åŒ–
    if MEDIAPIPE_AVAILABLE:
        # æ‰‹èªè­˜çµæœã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
        combined_mask = cv2.bitwise_or(skin_mask, hand_mask)
        # æ‰‹èªè­˜ã®ç²¾åº¦ãŒé«˜ã„å ´åˆã¯ã€ãã‚Œã‚’é‡è¦–
        if detection_info['hands_detected'] > 0:
            avg_confidence = detection_info['total_confidence'] / detection_info['hands_detected']
            if avg_confidence > 0.8:  # é«˜ä¿¡é ¼åº¦ã®å ´åˆ
                combined_mask = cv2.addWeighted(hand_mask, 0.7, skin_mask, 0.3, 0)
    else:
        combined_mask = skin_mask
    
    # ãƒã‚¤ã‚ºé™¤å»ï¼ˆè¨˜äº‹ã‚’å‚è€ƒã«æœ€é©åŒ–ï¼‰
    kernel = np.ones((5,5), np.uint8)
    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)
    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)
    
    # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã§æ»‘ã‚‰ã‹ã«
    combined_mask = cv2.GaussianBlur(combined_mask, (5, 5), 0)
    
    # è©³ç´°æƒ…å ±ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
    display_detection_info(img, detection_info)
    
    binary_img = cv2.merge([combined_mask, combined_mask, combined_mask])
    return binary_img, detection_info, landmarks_list, analysis_list

def create_precise_hand_mask(image, hand_landmarks):
    """è¨˜äº‹ã‚’å‚è€ƒã«ã—ãŸé«˜ç²¾åº¦æ‰‹ãƒã‚¹ã‚¯ä½œæˆ"""
    h, w, _ = image.shape
    mask = np.zeros((h, w), dtype=np.uint8)
    
    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‹ã‚‰æ‰‹ã®è¼ªéƒ­ã‚’ä½œæˆ
    landmarks = []
    for lm in hand_landmarks.landmark:
        x = int(lm.x * w)
        y = int(lm.y * h)
        landmarks.append([x, y])
    
    # ã‚ˆã‚Šæ­£ç¢ºãªæ‰‹ã®è¼ªéƒ­ã‚’å®šç¾©ï¼ˆè¨˜äº‹ã®æ‰‹æ³•ã‚’æ”¹è‰¯ï¼‰
    # æ‰‹ã®å¤–å´ã®è¼ªéƒ­ç‚¹ã‚’é †ç•ªã«æ¥ç¶š
    hand_outline = [
        landmarks[0],   # æ‰‹é¦–
        landmarks[1], landmarks[2], landmarks[3], landmarks[4],  # è¦ªæŒ‡
        landmarks[8],   # äººå·®ã—æŒ‡å…ˆ
        landmarks[12],  # ä¸­æŒ‡å…ˆ
        landmarks[16],  # è–¬æŒ‡å…ˆ
        landmarks[20],  # å°æŒ‡å…ˆ
        landmarks[19], landmarks[18], landmarks[17],  # å°æŒ‡å´é¢
        landmarks[5],   # äººå·®ã—æŒ‡ä»˜ã‘æ ¹
        landmarks[0]    # æ‰‹é¦–ã«æˆ»ã‚‹
    ]
    
    # ã‚ˆã‚Šæ»‘ã‚‰ã‹ãªè¼ªéƒ­ã®ãŸã‚ã«ç‚¹ã‚’è£œé–“
    pts = np.array(hand_outline, dtype=np.int32)
    cv2.fillPoly(mask, [pts], 255)
    
    # æŒ‡ã®é–“ã®éš™é–“ã‚‚åŸ‹ã‚ã‚‹ãŸã‚ã«ã€å„æŒ‡ã®å‘¨ã‚Šã«å††ã‚’æç”»
    finger_tip_ids = [4, 8, 12, 16, 20]
    for tip_id in finger_tip_ids:
        center = tuple(landmarks[tip_id])
        cv2.circle(mask, center, 20, 255, -1)
    
    # æ‰‹ã®ã²ã‚‰éƒ¨åˆ†ã‚‚ç¢ºå®Ÿã«å¡—ã‚Šã¤ã¶ã—
    palm_center_ids = [0, 5, 9, 13, 17]
    palm_points = [landmarks[i] for i in palm_center_ids]
    palm_pts = np.array(palm_points, dtype=np.int32)
    cv2.fillPoly(mask, [palm_pts], 255)
    
    return mask

def display_detection_info(image, detection_info):
    """æ¤œå‡ºæƒ…å ±ã‚’ç”»åƒã«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¡¨ç¤º"""
    y_offset = 30
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.7
    thickness = 2
    
    # åŸºæœ¬æƒ…å ±
    cv2.putText(image, f"Hands: {detection_info['hands_detected']}", 
               (10, y_offset), font, font_scale, (0, 255, 0), thickness)
    y_offset += 30
    
    if detection_info['hands_detected'] > 0:
        # å·¦å³ã®æ‰‹ã®æƒ…å ±
        cv2.putText(image, f"Left: {detection_info['left_hands']}, Right: {detection_info['right_hands']}", 
                   (10, y_offset), font, 0.6, (0, 255, 255), thickness)
        y_offset += 25
        
        # å¹³å‡ä¿¡é ¼åº¦
        avg_conf = detection_info['total_confidence'] / detection_info['hands_detected']
        cv2.putText(image, f"Avg Confidence: {avg_conf:.3f}", 
                   (10, y_offset), font, 0.6, (255, 255, 0), thickness)
        y_offset += 25
        
        # è©³ç´°åˆ†æçµæœ
        for i, analysis in enumerate(detection_info['hand_analyses']):
            cv2.putText(image, f"Hand {i+1}: {analysis['hand_label']} (Size: {analysis['hand_size']:.3f})", 
                       (10, y_offset), font, 0.5, (200, 200, 200), 1)
            y_offset += 20

# ===== ä½¿ç”¨å¯èƒ½ãªã‚«ãƒ¡ãƒ©ã‚’æ¢ã™ =====
def find_available_camera():
    for i in range(10):
        cap = cv2.VideoCapture(i)
        if cap.read()[0]:
            cap.release()
            return i
        cap.release()
    return -1

# ===== ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ é–¢é€£æ©Ÿèƒ½ï¼ˆå¤‰æ›´ãªã—ã€è¨˜äº‹ã®å“è³ªå‘ä¸Šã‚’é©ç”¨ï¼‰=====
def game_of_life_step(board):
    """é«˜é€ŸåŒ–ã•ã‚ŒãŸãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ ã®1ã‚¹ãƒ†ãƒƒãƒ—è¨ˆç®—"""
    rows, cols = board.shape
    padded = np.pad(board, pad_width=1, mode='constant', constant_values=0)
    
    kernel = np.array([[1, 1, 1],
                       [1, 0, 1],
                       [1, 1, 1]], dtype=np.uint8)
    
    neighbors = cv2.filter2D(padded, -1, kernel)[1:-1, 1:-1]
    
    new_board = np.zeros_like(board)
    new_board[(board == 1) & ((neighbors == 2) | (neighbors == 3))] = 1
    new_board[(board == 0) & (neighbors == 3)] = 1
    
    return new_board.astype(np.uint8)

def draw_board(board, scale=2, show_grid=False):
    """é«˜è§£åƒåº¦ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ ã®ç›¤é¢æç”»"""
    h, w = board.shape
    img = np.zeros((h*scale, w*scale, 3), dtype=np.uint8)
    
    # ã‚ˆã‚Šç¾ã—ã„ã‚»ãƒ«æç”»
    for i in range(h):
        for j in range(w):
            if board[i, j] == 1:
                y1, y2 = i*scale, (i+1)*scale
                x1, x2 = j*scale, (j+1)*scale
                
                # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åŠ¹æœ
                center_y, center_x = (y1 + y2) // 2, (x1 + x2) // 2
                cv2.circle(img, (center_x, center_y), scale//2, [255, 255, 255], -1)
                
                if scale >= 4:
                    cv2.circle(img, (center_x, center_y), max(1, scale//4), [255, 255, 255], -1)
    
    # ã‚°ãƒªãƒƒãƒ‰ç·šæç”»
    if show_grid and scale >= 3:
        grid_color = (64, 64, 64)
        for i in range(0, h*scale, scale):
            cv2.line(img, (0, i), (w*scale, i), grid_color, 1)
        for j in range(0, w*scale, scale):
            cv2.line(img, (j, 0), (j, h*scale), grid_color, 1)
    
    return img

def analyze_pattern(board, generation, history=None):
    """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã¨çµ±è¨ˆ"""
    alive_cells = np.sum(board)
    total_cells = board.shape[0] * board.shape[1]
    density = alive_cells / total_cells * 100
    
    is_stable = False
    is_oscillating = False
    
    if history is not None and len(history) > 1:
        # å‰ã®ä¸–ä»£ã¨æ¯”è¼ƒ
        if np.array_equal(board, history[-1]):
            is_stable = True
        
        # æŒ¯å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        if len(history) >= 3:
            for i in range(2, min(len(history), 6)):
                if np.array_equal(board, history[-i]):
                    is_oscillating = True
                    break
    
    return {
        'generation': generation,
        'alive_cells': int(alive_cells),
        'total_cells': total_cells,
        'density': density,
        'is_stable': is_stable,
        'is_oscillating': is_oscillating
    }

# ===== é«˜åº¦ãªãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ å®Ÿè¡Œï¼ˆè¨˜äº‹å“è³ªã§ã®åˆ†ææ©Ÿèƒ½ä»˜ãï¼‰=====
def run_advanced_life_game_from_array(mask, detection_info, landmarks_list, analysis_list, resolution=(1000, 800), speed=60):
    """è¨˜äº‹ãƒ¬ãƒ™ãƒ«ã®è©³ç´°åˆ†ææ©Ÿèƒ½ä»˜ããƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ """
    gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
    resized = cv2.resize(gray, resolution, interpolation=cv2.INTER_CUBIC)
    _, binary = cv2.threshold(resized, 50, 1, cv2.THRESH_BINARY)
    
    print(f"ğŸ® é«˜åº¦åˆ†æãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ é–‹å§‹ï¼({resolution[0]}x{resolution[1]})")
    print("=" * 60)
    print("æ‰‹èªè­˜åˆ†æçµæœ:")
    if detection_info['hands_detected'] > 0:
        print(f"  æ¤œå‡ºã•ã‚ŒãŸæ‰‹: {detection_info['hands_detected']}å€‹")
        print(f"  å·¦æ‰‹: {detection_info['left_hands']}å€‹, å³æ‰‹: {detection_info['right_hands']}å€‹")
        avg_conf = detection_info['total_confidence'] / detection_info['hands_detected']
        print(f"  å¹³å‡ä¿¡é ¼åº¦: {avg_conf:.3f}")
        
        for i, analysis in enumerate(analysis_list):
            print(f"  æ‰‹{i+1}: {analysis['hand_label']}, ã‚µã‚¤ã‚º: {analysis['hand_size']:.3f}")
    else:
        print("  æ‰‹ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆè‚Œè‰²æ¤œå‡ºã®ã¿ä½¿ç”¨ï¼‰")
    
    print("=" * 60)
    print("æ“ä½œæ–¹æ³•:")
    print("  ESC: çµ‚äº†")
    print("  SPACE: ä¸€æ™‚åœæ­¢/å†é–‹")
    print("  +/-: é€Ÿåº¦èª¿æ•´")
    print("  r: ãƒªã‚»ãƒƒãƒˆ")
    print("  g: ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ")
    print("  s: ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜")
    print("  i: è©³ç´°æƒ…å ±è¡¨ç¤º")
    print("  d: æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜")
    print("  h: ãƒ˜ãƒ«ãƒ—è¡¨ç¤º")
    print("=" * 60)
    
    original_binary = binary.copy()
    generation = 0
    paused = False
    show_grid = False
    current_speed = speed
    stats_height = 160
    
    # å±¥æ­´ä¿å­˜ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºç”¨ï¼‰
    history = []
    saved_data = []
    
    while True:
        if not paused:
            binary = game_of_life_step(binary)
            generation += 1
            
            # å±¥æ­´ã‚’ä¿å­˜ï¼ˆæœ€å¤§10ä¸–ä»£ï¼‰
            history.append(binary.copy())
            if len(history) > 10:
                history.pop(0)
        
        # çµ±è¨ˆåˆ†æ
        stats = analyze_pattern(binary, generation, history)
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢æç”»
        img = draw_board(binary, scale=2, show_grid=show_grid)
        
        # è©³ç´°çµ±è¨ˆæƒ…å ±ãƒ‘ãƒãƒ«
        stats_img = np.zeros((stats_height, img.shape[1], 3), dtype=np.uint8)
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        color = (255, 255, 255)
        thickness = 1
        
        # åŸºæœ¬çµ±è¨ˆï¼ˆå·¦åˆ—ï¼‰
        cv2.putText(stats_img, f"Generation: {stats['generation']}", 
                   (10, 25), font, font_scale, color, thickness)
        cv2.putText(stats_img, f"Alive Cells: {stats['alive_cells']}/{stats['total_cells']}", 
                   (10, 50), font, font_scale, color, thickness)
        cv2.putText(stats_img, f"Density: {stats['density']:.2f}%", 
                   (10, 75), font, font_scale, color, thickness)
        
        # æ‰‹èªè­˜æƒ…å ±
        detection_text = f"Hand Detection: {'ADVANCED' if MEDIAPIPE_AVAILABLE else 'BASIC'}"
        detection_color = (0, 255, 0) if MEDIAPIPE_AVAILABLE else (255, 255, 0)
        cv2.putText(stats_img, detection_text, 
                   (10, 100), font, font_scale, detection_color, thickness)
        
        # æ¤œå‡ºã•ã‚ŒãŸæ‰‹ã®è©³ç´°æƒ…å ±
        if detection_info['hands_detected'] > 0:
            hands_text = f"Hands: {detection_info['hands_detected']} (L:{detection_info['left_hands']}, R:{detection_info['right_hands']})"
            cv2.putText(stats_img, hands_text, 
                       (10, 125), font, 0.5, (0, 255, 255), thickness)
            
            avg_conf = detection_info['total_confidence'] / detection_info['hands_detected']
            cv2.putText(stats_img, f"Confidence: {avg_conf:.3f}", 
                       (10, 145), font, 0.5, (255, 255, 0), thickness)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³çŠ¶æ…‹ï¼ˆä¸­å¤®åˆ—ï¼‰
        pattern_x = 350
        if stats['is_stable']:
            cv2.putText(stats_img, "Pattern: STABLE", 
                       (pattern_x, 25), font, font_scale, (0, 255, 255), thickness)
        elif stats['is_oscillating']:
            cv2.putText(stats_img, "Pattern: OSCILLATING", 
                       (pattern_x, 25), font, font_scale, (255, 0, 255), thickness)
        else:
            cv2.putText(stats_img, "Pattern: EVOLVING", 
                       (pattern_x, 25), font, font_scale, (255, 255, 0), thickness)
        
        # å³å´ã®æ“ä½œæƒ…å ±
        cv2.putText(stats_img, f"Speed: {current_speed}ms", 
                   (pattern_x, 50), font, font_scale, color, thickness)
        status_color = (0, 255, 255) if paused else (0, 255, 0)
        cv2.putText(stats_img, f"Status: {'PAUSED' if paused else 'RUNNING'}", 
                   (pattern_x, 75), font, font_scale, status_color, thickness)
        cv2.putText(stats_img, f"Grid: {'ON' if show_grid else 'OFF'}", 
                   (pattern_x, 100), font, font_scale, color, thickness)
        
        resolution_text = f"Resolution: {resolution[0]}x{resolution[1]}"
        cv2.putText(stats_img, resolution_text, 
                   (pattern_x, 125), font, font_scale, color, thickness)
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜æƒ…å ±
        cv2.putText(stats_img, f"Saved Data: {len(saved_data)} frames", 
                   (pattern_x, 145), font, 0.5, (200, 200, 200), thickness)
        
        # ç”»åƒã‚’çµåˆ
        combined_img = np.vstack((img, stats_img))
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«è¡¨ç¤º
        cv2.imshow("Advanced Hand-Enhanced Conway's Game of Life", combined_img)
        
        # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
        key = cv2.waitKey(current_speed) & 0xFF
        
        if key == 27:  # ESC - çµ‚äº†
            print("ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ çµ‚äº†")
            break
        elif key == 32:  # SPACE - ä¸€æ™‚åœæ­¢/å†é–‹
            paused = not paused
            print(f"{'ä¸€æ™‚åœæ­¢' if paused else 'å†é–‹'}")
        elif key == ord('r'):  # r - ãƒªã‚»ãƒƒãƒˆ
            binary = original_binary.copy()
            generation = 0
            paused = False
            history.clear()
            saved_data.clear()
            print("ã‚²ãƒ¼ãƒ ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
        elif key == ord('g'):  # g - ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ
            show_grid = not show_grid
            print(f"ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º: {'ON' if show_grid else 'OFF'}")
        elif key == ord('+') or key == ord('='):  # + - é€Ÿåº¦ä¸Šã’ã‚‹
            current_speed = max(10, current_speed - 20)
            print(f"é€Ÿåº¦: {current_speed}ms")
        elif key == ord('-'):  # - - é€Ÿåº¦ä¸‹ã’ã‚‹
            current_speed = min(1000, current_speed + 20)
            print(f"é€Ÿåº¦: {current_speed}ms")
        elif key == ord('s'):  # s - ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"advanced_life_game_{timestamp}_gen_{generation}.png"
            cv2.imwrite(filename, combined_img)
            print(f"ğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜: {filename}")
        elif key == ord('d'):  # d - æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if MEDIAPIPE_AVAILABLE and landmarks_list:
                hand_tracker = AdvancedHandTracker()  # ä¸€æ™‚çš„ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
                data = hand_tracker.save_detection_data(landmarks_list, analysis_list, generation)
                saved_data.append(data)
                
                # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                json_filename = f"hand_detection_data_{timestamp}.json"
                with open(json_filename, 'w', encoding='utf-8') as f:
                    json.dump(saved_data, f, indent=2, ensure_ascii=False)
                print(f"ğŸ’¾ æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜: {json_filename}")
            else:
                print("âš ï¸ ä¿å­˜ã§ãã‚‹æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        elif key == ord('i'):  # i - è©³ç´°æƒ…å ±
            print(f"\n=== è©³ç´°åˆ†ææƒ…å ± (Generation {generation}) ===")
            print(f"ç”Ÿå­˜ã‚»ãƒ«æ•°: {stats['alive_cells']}")
            print(f"ç·ã‚»ãƒ«æ•°: {stats['total_cells']}")
            print(f"å¯†åº¦: {stats['density']:.2f}%")
            print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³çŠ¶æ…‹: {'å®‰å®š' if stats['is_stable'] else 'æŒ¯å‹•' if stats['is_oscillating'] else 'é€²åŒ–ä¸­'}")
            print(f"æ‰‹èªè­˜ãƒ¢ãƒ¼ãƒ‰: {'é«˜åº¦åˆ†æ' if MEDIAPIPE_AVAILABLE else 'åŸºæœ¬ãƒ¢ãƒ¼ãƒ‰'}")
            
            if detection_info['hands_detected'] > 0:
                print("\næ‰‹èªè­˜è©³ç´°:")
                for i, analysis in enumerate(analysis_list):
                    print(f"  æ‰‹ {i+1}:")
                    print(f"    ãƒ©ãƒ™ãƒ«: {analysis['hand_label']}")
                    print(f"    ä¿¡é ¼åº¦: {analysis['confidence']:.3f}")
                    print(f"    æ‰‹ã®ã‚µã‚¤ã‚º: {analysis['hand_size']:.3f}")
                    print(f"    æ‰‹ã®ã²ã‚‰ä¸­å¿ƒ: ({analysis['palm_center'][0]:.3f}, {analysis['palm_center'][1]:.3f})")
                    print(f"    æŒ‡å…ˆåº§æ¨™æ•°: {len(analysis['fingertip_coords'])}")
        elif key == ord('h'):  # h - ãƒ˜ãƒ«ãƒ—
            print("\n" + "=" * 70)
            print("ğŸ–ï¸ é«˜åº¦æ‰‹èªè­˜ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ  - ãƒ˜ãƒ«ãƒ—")
            print("=" * 70)
            print("ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯è¨˜äº‹ã€Mediapipeã§æ‰‹ã®å½¢çŠ¶æ¤œå‡ºã‚’è©¦ã—ã¦ã¿ãŸã€ã®æ‰‹æ³•ã‚’")
            print("ãƒ™ãƒ¼ã‚¹ã«ã€ã‚ˆã‚Šé«˜åº¦ãªæ‰‹èªè­˜ã¨ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ ã®çµ„ã¿åˆã‚ã›ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚")
            print()
            print("ğŸ“Š åˆ†ææ©Ÿèƒ½:")
            print("  â€¢ 21ç‚¹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¿½è·¡")
            print("  â€¢ å·¦å³ã®æ‰‹ã®è‡ªå‹•åˆ¤å®š")
            print("  â€¢ ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¡¨ç¤º")
            print("  â€¢ æ‰‹ã®ã‚µã‚¤ã‚ºãƒ»ä¸­å¿ƒåº§æ¨™è¨ˆç®—")
            print("  â€¢ æŒ‡å…ˆåº§æ¨™ã®è©³ç´°è¿½è·¡")
            print()
            print("ğŸ® ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ æ©Ÿèƒ½:")
            print("  â€¢ ãƒ‘ã‚¿ãƒ¼ãƒ³çŠ¶æ…‹ã®è‡ªå‹•åˆ¤å®šï¼ˆå®‰å®š/æŒ¯å‹•/é€²åŒ–ï¼‰")
            print("  â€¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµ±è¨ˆè¡¨ç¤º")
            print("  â€¢ é«˜è§£åƒåº¦æç”»")
            print("  â€¢ ãƒ‡ãƒ¼ã‚¿ä¿å­˜æ©Ÿèƒ½")
            print()
            print("ğŸ’¾ ä¿å­˜ã•ã‚Œã‚‹æƒ…å ±:")
            print("  â€¢ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼ˆs ã‚­ãƒ¼ï¼‰")
            print("  â€¢ æ‰‹èªè­˜ãƒ‡ãƒ¼ã‚¿ï¼ˆd ã‚­ãƒ¼ã€JSONå½¢å¼ï¼‰")
            print("  â€¢ ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™")
            print("  â€¢ ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢")
            print("=" * 70)
    
    cv2.destroyAllWindows()

# ===== ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ =====
def create_preset_pattern(pattern_name, size=(1000, 800)):
    """é«˜å“è³ªãƒ—ãƒªã‚»ãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ"""
    board = np.zeros(size[::-1], dtype=np.uint8)
    h, w = board.shape
    center_y, center_x = h // 2, w // 2
    
    if pattern_name == "glider":
        # è¤‡æ•°ã®ã‚°ãƒ©ã‚¤ãƒ€ãƒ¼é…ç½®
        glider = np.array([[0, 1, 0],
                          [0, 0, 1],
                          [1, 1, 1]], dtype=np.uint8)
        # è¤‡æ•°ç®‡æ‰€ã«é…ç½®
        positions = [
            (center_y-50, center_x-50),
            (center_y+50, center_x+50),
            (center_y-100, center_x+100)
        ]
        for py, px in positions:
            if py >= 0 and px >= 0 and py+3 <= h and px+3 <= w:
                board[py:py+3, px:px+3] = glider
                
    elif pattern_name == "oscillator":
        # è¤‡æ•°ã®æŒ¯å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns = [
            # ãƒ“ãƒ¼ã‚³ãƒ³
            [(center_y-1, center_x-1, 2, 2), (center_y+1, center_x+1, 2, 2)],
            # ãƒ–ãƒªãƒ³ã‚«ãƒ¼
            [(center_y-50, center_x-50, 1, 3)],
            [(center_y+50, center_x+50, 3, 1)]
        ]
        for pattern in patterns:
            for py, px, h_size, w_size in pattern:
                if py >= 0 and px >= 0 and py+h_size <= h and px+w_size <= w:
                    board[py:py+h_size, px:px+w_size] = 1
                    
    elif pattern_name == "random":
        # ã‚ˆã‚Šèˆˆå‘³æ·±ã„ãƒ©ãƒ³ãƒ€ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³
        board = np.random.choice([0, 1], size=(h, w), p=[0.75, 0.25]).astype(np.uint8)
        
        # ä¸­å¤®ã«é«˜å¯†åº¦é ˜åŸŸã‚’ä½œæˆ
        center_region = board[center_y-100:center_y+100, center_x-100:center_x+100]
        high_density = np.random.choice([0, 1], size=center_region.shape, p=[0.5, 0.5])
        board[center_y-100:center_y+100, center_x-100:center_x+100] = high_density
        
    elif pattern_name == "pulsar":
        # ãƒ‘ãƒ«ã‚µãƒ¼ï¼ˆå‘¨æœŸ15ã®æŒ¯å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        pulsar_pattern = [
            [0,0,1,1,1,0,0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0,0,0,0,0,0,0],
            [1,0,0,0,0,1,0,1,0,0,0,0,1],
            [1,0,0,0,0,1,0,1,0,0,0,0,1],
            [1,0,0,0,0,1,0,1,0,0,0,0,1],
            [0,0,1,1,1,0,0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0,0,1,1,1,0,0],
            [1,0,0,0,0,1,0,1,0,0,0,0,1],
            [1,0,0,0,0,1,0,1,0,0,0,0,1],
            [1,0,0,0,0,1,0,1,0,0,0,0,1],
            [0,0,0,0,0,0,0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0,0,1,1,1,0,0]
        ]
        pulsar = np.array(pulsar_pattern, dtype=np.uint8)
        py, px = pulsar.shape
        
        # è¤‡æ•°ã®ãƒ‘ãƒ«ã‚µãƒ¼ã‚’é…ç½®
        positions = [
            (center_y-py//2, center_x-px//2),
            (center_y-py//2-80, center_x-px//2-80),
            (center_y-py//2+80, center_x-px//2+80)
        ]
        for pos_y, pos_x in positions:
            if pos_y >= 0 and pos_x >= 0 and pos_y+py <= h and pos_x+px <= w:
                board[pos_y:pos_y+py, pos_x:pos_x+px] = pulsar
    
    return board

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆè¨˜äº‹å“è³ªã®å®Œå…¨ç‰ˆï¼‰=====
def main():
    print("ğŸ–ï¸ === é«˜åº¦æ‰‹èªè­˜å¯¾å¿œ ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ  ===")
    print("Qiitaè¨˜äº‹ã€Mediapipeã§æ‰‹ã®å½¢çŠ¶æ¤œå‡ºã‚’è©¦ã—ã¦ã¿ãŸã€ãƒ™ãƒ¼ã‚¹")
    print("21ç‚¹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¿½è·¡ + è©³ç´°åˆ†ææ©Ÿèƒ½æ­è¼‰ï¼")
    print()
    
    if MEDIAPIPE_AVAILABLE:
        print("âœ… MediaPipe: åˆ©ç”¨å¯èƒ½ - é«˜ç²¾åº¦æ‰‹èªè­˜æ©Ÿèƒ½ON")
        print("   â€¢ 21ç‚¹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¿½è·¡")
        print("   â€¢ å·¦å³ã®æ‰‹è‡ªå‹•åˆ¤å®š")
        print("   â€¢ ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¡¨ç¤º")
        print("   â€¢ æŒ‡å…ˆåº§æ¨™è©³ç´°åˆ†æ")
    else:
        print("âš ï¸  MediaPipe: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - åŸºæœ¬è‚Œè‰²æ¤œå‡ºã®ã¿")
        print("   pip install mediapipe ã§ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰å¯èƒ½")
    
    # é«˜åº¦æ‰‹è¿½è·¡å™¨ã‚’åˆæœŸåŒ–
    hand_tracker = AdvancedHandTracker()
    
    cam_index = find_available_camera()
    if cam_index == -1:
        print("\nğŸ“· ã‚«ãƒ¡ãƒ©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼")
        print("ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/n)")
        if input().lower() == 'y':
            print("\nãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„:")
            print("1. ã‚°ãƒ©ã‚¤ãƒ€ãƒ¼ï¼ˆç§»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³Ã—3ï¼‰")
            print("2. æŒ¯å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆè¤‡æ•°ã®æŒ¯å‹•å­ï¼‰")
            print("3. ãƒ‘ãƒ«ã‚µãƒ¼ï¼ˆè¤‡é›‘ãªå‘¨æœŸãƒ‘ã‚¿ãƒ¼ãƒ³Ã—3ï¼‰")
            print("4. ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆé«˜å¯†åº¦ä¸­å¤®é ˜åŸŸä»˜ãï¼‰")
            choice = input("é¸æŠ (1-4): ")
            
            patterns = {
                "1": "glider", 
                "2": "oscillator", 
                "3": "pulsar",
                "4": "random"
            }
            if choice in patterns:
                print(f"\n{patterns[choice]}ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆä¸­...")
                board = create_preset_pattern(patterns[choice])
                mask = np.stack([board*255]*3, axis=-1).astype(np.uint8)
                
                # ç©ºã®æ¤œå‡ºæƒ…å ±ã‚’ä½œæˆ
                empty_detection_info = {
                    'hands_detected': 0,
                    'left_hands': 0,
                    'right_hands': 0,
                    'total_confidence': 0,
                    'hand_analyses': []
                }
                
                run_advanced_life_game_from_array(
                    mask, empty_detection_info, [], [], 
                    resolution=(1000, 800)
                )
        return

    # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
    cap = cv2.VideoCapture(cam_index)
    if not cap.isOpened():
        print("âŒ ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ï¼")
        return

    # ã‚«ãƒ¡ãƒ©è¨­å®šï¼ˆé«˜è§£åƒåº¦ï¼‰
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    cap.set(cv2.CAP_PROP_FPS, 30)

    print(f"\nğŸ“· ã‚«ãƒ¡ãƒ© {cam_index} ã‚’èµ·å‹•ã—ã¾ã—ãŸ")
    print("ğŸ”´ é«˜åº¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ‰‹èªè­˜ä¸­...")
    print("\næ“ä½œæ–¹æ³•:")
    print("  SPACE: æ’®å½±ã—ã¦ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ é–‹å§‹")
    print("  ESC: çµ‚äº†")
    print("  h: æ‰‹èªè­˜è©³ç´°æƒ…å ±è¡¨ç¤º")
    print("  c: ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±")
    print("  s: æ¤œå‡ºçµ±è¨ˆè¡¨ç¤º")
    print("  d: ç¾åœ¨ã®æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜")
    print("  f: ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³åˆ‡ã‚Šæ›¿ãˆ")
    print("=" * 60)

    fullscreen = False
    frame_count = 0
    fps_timer = time.time()
    current_fps = 0
    last_detection_info = {}
    last_landmarks_list = []
    last_analysis_list = []

    # æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs("detection_data", exist_ok=True)
    os.makedirs("screenshots", exist_ok=True)

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ ã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ï¼")
            break

        frame_count += 1
        
        # FPSè¨ˆç®—
        if frame_count % 30 == 0:
            current_time = time.time()
            current_fps = 30 / (current_time - fps_timer)
            fps_timer = current_time

        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ°´å¹³åè»¢ï¼ˆé¡åƒåŠ¹æœï¼‰
        frame = cv2.flip(frame, 1)
        
        # é«˜åº¦ãªæ‰‹èªè­˜ã¨è‚Œè‰²æ¤œå‡ºã‚’å®Ÿè¡Œ
        display_frame = frame.copy()
        mask, detection_info, landmarks_list, analysis_list = enhanced_skin_mask_with_analysis(
            display_frame, hand_tracker
        )
        
        # æœ€æ–°ã®æ¤œå‡ºçµæœã‚’ä¿å­˜
        last_detection_info = detection_info
        last_landmarks_list = landmarks_list
        last_analysis_list = analysis_list
        
        # FPSæƒ…å ±è¡¨ç¤º
        cv2.putText(display_frame, f"FPS: {current_fps:.1f}", 
                   (display_frame.shape[1] - 150, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°è¡¨ç¤º
        cv2.putText(display_frame, f"Frame: {frame_count}", 
                   (display_frame.shape[1] - 150, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
        
        # æ¤œå‡ºçµ±è¨ˆè¡¨ç¤º
        if MEDIAPIPE_AVAILABLE:
            stats = hand_tracker.get_detection_statistics()
            if stats:
                cv2.putText(display_frame, f"Detection Rate: {stats['detection_rate']:.1f}%", 
                           (display_frame.shape[1] - 200, 90), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        
        # æ“ä½œã‚¬ã‚¤ãƒ‰
        guide_y = display_frame.shape[0] - 90
        cv2.putText(display_frame, "SPACE: Capture & Start Advanced Life Game", 
                   (10, guide_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(display_frame, "ESC: Exit | H: Hand Info | S: Statistics | D: Save Data", 
                   (10, guide_y + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 2)
        cv2.putText(display_frame, "C: Calibration | F: Fullscreen", 
                   (10, guide_y + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 2)
        
        # çµæœã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        combined = np.hstack((display_frame, mask))
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºèª¿æ•´
        if fullscreen:
            cv2.namedWindow("Advanced Hand Recognition + Life Game", cv2.WINDOW_NORMAL)
            cv2.setWindowProperty("Advanced Hand Recognition + Life Game", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
            cv2.imshow("Advanced Hand Recognition + Life Game", combined)
        else:
            display_width = 1600
            display_height = int(combined.shape[0] * display_width / combined.shape[1])
            resized_combined = cv2.resize(combined, (display_width, display_height))
            cv2.imshow("Advanced Hand Recognition + Life Game", resized_combined)

        # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
        key = cv2.waitKey(1) & 0xFF

        if key == 27:  # ESC - çµ‚äº†
            print("ğŸ‘‹ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†")
            break
            
        elif key == 32:  # SPACE - æ’®å½±ã—ã¦ãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ é–‹å§‹
            # é«˜å“è³ªãªç”»åƒã¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ç”»åƒä¿å­˜
            image_filename = f"screenshots/captured_hand_advanced_{timestamp}.png"
            cv2.imwrite(image_filename, mask)
            
            # æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if MEDIAPIPE_AVAILABLE and landmarks_list:
                data_filename = f"detection_data/capture_data_{timestamp}.json"
                capture_data = hand_tracker.save_detection_data(
                    landmarks_list, analysis_list, frame_count
                )
                with open(data_filename, 'w', encoding='utf-8') as f:
                    json.dump(capture_data, f, indent=2, ensure_ascii=False)
                print(f"ğŸ’¾ æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜: {data_filename}")
            
            print(f"ğŸ“¸ é«˜åº¦æ‰‹èªè­˜ç”»åƒã‚­ãƒ£ãƒ—ãƒãƒ£å®Œäº†: {image_filename}")
            print("ğŸ® é«˜åº¦åˆ†æãƒ©ã‚¤ãƒ•ã‚²ãƒ¼ãƒ é–‹å§‹ï¼")
            
            time.sleep(0.1)  # ä¿å­˜å®Œäº†ã‚’å¾…ã¤
            run_advanced_life_game_from_array(
                mask, detection_info, landmarks_list, analysis_list,
                resolution=(1200, 900), speed=50
            )
            
            print("ğŸ“· ã‚«ãƒ¡ãƒ©ç”»é¢ã«æˆ»ã‚Šã¾ã—ãŸ")
            
        elif key == ord('h'):  # h - æ‰‹èªè­˜è©³ç´°æƒ…å ±
            print("\n" + "=" * 80)
            print("ğŸ–ï¸  é«˜åº¦æ‰‹èªè­˜è©³ç´°æƒ…å ±")
            print("=" * 80)
            if MEDIAPIPE_AVAILABLE:
                print("âœ… MediaPipeæ‰‹èªè­˜: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
                print(f"   æ¤œå‡ºã•ã‚ŒãŸæ‰‹ã®æ•°: {detection_info['hands_detected']}")
                if detection_info['hands_detected'] > 0:
                    print("   æ©Ÿèƒ½:")
                    print("     â€¢ 21ç‚¹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¿½è·¡")
                    print("     â€¢ å·¦å³ã®æ‰‹è‡ªå‹•åˆ¤å®š")
                    print("     â€¢ ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—")
                    print("     â€¢ æŒ‡å…ˆåº§æ¨™è©³ç´°åˆ†æ")
                    print("     â€¢ æ‰‹ã®ã‚µã‚¤ã‚ºãƒ»ä¸­å¿ƒåº§æ¨™è¨ˆç®—")
                    print("     â€¢ éª¨æ ¼æç”» + æ¥ç¶šç·šè¡¨ç¤º")
                    print("     â€¢ è‰²åˆ†ã‘è¡¨ç¤ºï¼ˆæŒ‡åˆ¥ï¼‰")
                    
                    print("\n   æ¤œå‡ºè©³ç´°:")
                    for i, analysis in enumerate(analysis_list):
                        print(f"     æ‰‹ {i+1}:")
                        print(f"       ãƒ©ãƒ™ãƒ«: {analysis['hand_label']}")
                        print(f"       ä¿¡é ¼åº¦: {analysis['confidence']:.4f}")
                        print(f"       æ‰‹ã®ã‚µã‚¤ã‚º: {analysis['hand_size']:.4f}")
                        print(f"       æ‰‹ã®ã²ã‚‰ä¸­å¿ƒ: ({analysis['palm_center'][0]:.4f}, {analysis['palm_center'][1]:.4f})")
                        print(f"       ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ•°: {len(analysis['landmark_coords'])}")
                        
                        # æŒ‡å…ˆåº§æ¨™ã‚’è¡¨ç¤º
                        print(f"       æŒ‡å…ˆåº§æ¨™:")
                        for fingertip in analysis['fingertip_coords']:
                            print(f"         {fingertip['finger']}: ({fingertip['x']:.4f}, {fingertip['y']:.4f}, {fingertip['z']:.4f})")
                else:
                    print("   çŠ¶æ…‹: æ‰‹ã‚’æ¤œå‡ºä¸­...")
                    print("   ãƒ’ãƒ³ãƒˆ: æ‰‹ã‚’ã‚«ãƒ¡ãƒ©ã«å‘ã‘ã¦ãã ã•ã„")
                    print("   å¯¾å¿œ: è‚Œè‰²ã€æ¨™æº–çš„ãªæ‰‹ã®å½¢ã€æ˜ã‚‹ã„ç’°å¢ƒ")
            else:
                print("âš ï¸  åŸºæœ¬ãƒ¢ãƒ¼ãƒ‰: è‚Œè‰²æ¤œå‡ºã®ã¿")
                print("   æ©Ÿèƒ½: HSV + YCrCbè‰²ç©ºé–“ã«ã‚ˆã‚‹è‚Œè‰²æ¤œå‡º")
                print("   ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰: pip install mediapipe")
            
            # æ¤œå‡ºçµ±è¨ˆ
            if MEDIAPIPE_AVAILABLE:
                stats = hand_tracker.get_detection_statistics()
                if stats:
                    print(f"\nğŸ“Š æ¤œå‡ºçµ±è¨ˆ:")
                    print(f"   ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {stats['total_frames']}")
                    print(f"   æ¤œå‡ºã•ã‚ŒãŸæ‰‹: {stats['hands_detected']}")
                    print(f"   å·¦æ‰‹: {stats['left_hands']}, å³æ‰‹: {stats['right_hands']}")
                    print(f"   æ¤œå‡ºç‡: {stats['detection_rate']:.2f}%")
                    print(f"   å¹³å‡ä¿¡é ¼åº¦: {stats['average_confidence']:.4f}")
                    if stats['confidence_scores']:
                        print(f"   æœ€æ–°ä¿¡é ¼åº¦: {stats['confidence_scores'][-1]:.4f}")
            
            print("=" * 80)
            
        elif key == ord('c'):  # c - ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±
            print("\n" + "=" * 80)
            print("ğŸ”§ é«˜åº¦ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±")
            print("=" * 80)
            print("æœ€é©ãªæ¤œå‡ºã®ãŸã‚ã®è©³ç´°ãƒ’ãƒ³ãƒˆ:")
            print()
            print("ğŸŒ ç’°å¢ƒè¨­å®š:")
            print("  â€¢ æ˜ã‚‹ãå‡ä¸€ãªç…§æ˜ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
            print("  â€¢ ç›´æ¥å…‰ã‚„å½±ã‚’é¿ã‘ã¦ãã ã•ã„")
            print("  â€¢ èƒŒæ™¯ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«ä¿ã£ã¦ãã ã•ã„ï¼ˆå˜è‰²æ¨å¥¨ï¼‰")
            print("  â€¢ ã‚«ãƒ¡ãƒ©ã‹ã‚‰30-60cmç¨‹åº¦ã®è·é›¢ã‚’ä¿ã£ã¦ãã ã•ã„")
            print()
            print("âœ‹ æ‰‹ã®çŠ¶æ…‹:")
            print("  â€¢ æ‰‹å…¨ä½“ãŒãƒ•ãƒ¬ãƒ¼ãƒ å†…ã«å…¥ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„")
            print("  â€¢ æŒ‡ã‚’ã§ãã‚‹ã ã‘é–‹ã„ã¦ãã ã•ã„")
            print("  â€¢ æ‰‹è¢‹ã¯å¤–ã—ã¦ãã ã•ã„")
            print("  â€¢ è¤‡æ•°ã®æ‰‹ã‚’åŒæ™‚ã«æ¤œå‡ºå¯èƒ½ã§ã™ï¼ˆæœ€å¤§2ã¤ï¼‰")
            print("  â€¢ å·¦å³ã®æ‰‹ã¯è‡ªå‹•ã§åˆ¤å®šã•ã‚Œã¾ã™")
            print()
            if MEDIAPIPE_AVAILABLE:
                print("ğŸ¯ MediaPipeç‰¹æœ‰ã®æ³¨æ„ç‚¹:")
                print("  â€¢ æ¨™æº–çš„ãªè‚Œè‰²ã§ã®æ¤œå‡ºç²¾åº¦ãŒæœ€ã‚‚é«˜ã„ã§ã™")
                print("  â€¢ ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚„éç¾å®Ÿçš„ãªæ‰‹ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“")
                print("  â€¢ è¤‡é›‘ã™ãã‚‹æ‰‹ã®ãƒãƒ¼ã‚ºã¯ä¸€éƒ¨èª¤æ¤œå‡ºã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                print("  â€¢ å¥¥è¡Œãæƒ…å ±ï¼ˆzåº§æ¨™ï¼‰ã‚‚å–å¾—ã•ã‚Œã¾ã™")
                print("  â€¢ éš ã‚ŒãŸæŒ‡ã‚‚æ¨å®šãƒ»è£œå®Œã•ã‚Œã¾ã™")
            print("=" * 80)
            
        elif key == ord('s'):  # s - æ¤œå‡ºçµ±è¨ˆè¡¨ç¤º
            print(f"\nğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡ºçµ±è¨ˆ:")
            print(f"ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ : {frame_count}")
            print(f"ç¾åœ¨ã®FPS: {current_fps:.2f}")
            
            if MEDIAPIPE_AVAILABLE:
                stats = hand_tracker.get_detection_statistics()
                if stats:
                    print(f"\næ¤œå‡ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
                    print(f"  ç·å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {stats['total_frames']}")
                    print(f"  æ¤œå‡ºæˆåŠŸæ•°: {stats['hands_detected']}")
                    print(f"  æ¤œå‡ºç‡: {stats['detection_rate']:.2f}%")
                    print(f"  å·¦æ‰‹æ¤œå‡ºæ•°: {stats['left_hands']}")
                    print(f"  å³æ‰‹æ¤œå‡ºæ•°: {stats['right_hands']}")
                    print(f"  å¹³å‡ä¿¡é ¼åº¦: {stats['average_confidence']:.4f}")
                    
                    if stats['confidence_scores']:
                        recent_scores = stats['confidence_scores']
                        print(f"  æœ€æ–°ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢:")
                        for i, score in enumerate(recent_scores[-5:]):  # æœ€æ–°5å€‹
                            print(f"    {i+1}: {score:.4f}")
            
            print(f"\nç¾åœ¨ã®æ¤œå‡ºçŠ¶æ³:")
            if detection_info['hands_detected'] > 0:
                print(f"  æ¤œå‡ºä¸­ã®æ‰‹: {detection_info['hands_detected']}å€‹")
                print(f"  å·¦æ‰‹: {detection_info['left_hands']}å€‹")
                print(f"  å³æ‰‹: {detection_info['right_hands']}å€‹")
                avg_conf = detection_info['total_confidence'] / detection_info['hands_detected']
                print(f"  ç¾åœ¨ã®å¹³å‡ä¿¡é ¼åº¦: {avg_conf:.4f}")
            else:
                print("  ç¾åœ¨æ‰‹ã¯æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
        elif key == ord('d'):  # d - ç¾åœ¨ã®æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if MEDIAPIPE_AVAILABLE and landmarks_list:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # è©³ç´°ãªæ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                save_data = {
                    'timestamp': timestamp,
                    'frame_number': frame_count,
                    'fps': current_fps,
                    'detection_info': detection_info,
                    'hand_analyses': analysis_list,
                    'detection_statistics': hand_tracker.get_detection_statistics()
                }
                
                # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ã‚‚è©³ç´°ã«ä¿å­˜
                detailed_landmarks = []
                for i, landmarks in enumerate(landmarks_list):
                    landmark_data = {
                        'hand_id': i,
                        'coordinates': landmarks,
                        'analysis': analysis_list[i] if i < len(analysis_list) else {}
                    }
                    detailed_landmarks.append(landmark_data)
                
                save_data['detailed_landmarks'] = detailed_landmarks
                
                filename = f"detection_data/realtime_data_{timestamp}.json"
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(save_data, f, indent=2, ensure_ascii=False)
                
                print(f"ğŸ’¾ ç¾åœ¨ã®æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {filename}")
                
                # ç”»åƒã‚‚åŒæ™‚ä¿å­˜
                image_filename = f"screenshots/realtime_capture_{timestamp}.png"
                cv2.imwrite(image_filename, combined)
                print(f"ğŸ“¸ ç¾åœ¨ã®ç”»é¢ã‚‚ä¿å­˜: {image_filename}")
            else:
                print("âš ï¸ ä¿å­˜ã§ãã‚‹æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                
        elif key == ord('f'):  # f - ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³åˆ‡ã‚Šæ›¿ãˆ
            fullscreen = not fullscreen
            if not fullscreen:
                cv2.namedWindow("Advanced Hand Recognition + Life Game", cv2.WINDOW_AUTOSIZE)
            print(f"ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³: {'ON' if fullscreen else 'OFF'}")
            
        elif key == ord('q'):  # q - å“è³ªãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±
            print(f"\nğŸ“ˆ ã‚·ã‚¹ãƒ†ãƒ å“è³ªæƒ…å ±:")
            print(f"ã‚«ãƒ¡ãƒ©è§£åƒåº¦: {frame.shape[1]}x{frame.shape[0]}")
            print(f"ã‚«ãƒ©ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹: BGR â†’ RGB (MediaPipeç”¨)")
            print(f"å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {'é«˜ç²¾åº¦MediaPipe' if MEDIAPIPE_AVAILABLE else 'åŸºæœ¬è‚Œè‰²æ¤œå‡º'}")
            print(f"ç¾åœ¨ã®FPS: {current_fps:.2f}")
            print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†æ•°: {frame_count}")
            
            if MEDIAPIPE_AVAILABLE:
                print(f"MediaPipeè¨­å®š:")
                print(f"  static_image_mode: False")
                print(f"  max_num_hands: 2")
                print(f"  min_detection_confidence: 0.7")
                print(f"  min_tracking_confidence: 0.5")
                
        elif key == ord('r'):  # r - çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ
            if MEDIAPIPE_AVAILABLE:
                hand_tracker.detection_stats = {
                    'total_frames': 0,
                    'hands_detected': 0,
                    'left_hands': 0,
                    'right_hands': 0,
                    'confidence_scores': []
                }
                print("ğŸ“Š æ¤œå‡ºçµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
            frame_count = 0
            fps_timer = time.time()
            print("ğŸ“ˆ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

    # ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
    cap.release()
    cv2.destroyAllWindows()
    
    if MEDIAPIPE_AVAILABLE and hand_tracker.hands:
        hand_tracker.hands.close()
    
    # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
    if MEDIAPIPE_AVAILABLE:
        final_stats = hand_tracker.get_detection_statistics()
        if final_stats:
            print("\n" + "=" * 60)
            print("ğŸ“Š æœ€çµ‚æ¤œå‡ºçµ±è¨ˆ")
            print("=" * 60)
            print(f"ç·å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {final_stats['total_frames']}")
            print(f"æ‰‹æ¤œå‡ºæˆåŠŸæ•°: {final_stats['hands_detected']}")
            print(f"æœ€çµ‚æ¤œå‡ºç‡: {final_stats['detection_rate']:.2f}%")
            print(f"å·¦æ‰‹æ¤œå‡ºæ•°: {final_stats['left_hands']}")
            print(f"å³æ‰‹æ¤œå‡ºæ•°: {final_stats['right_hands']}")
            print(f"å¹³å‡ä¿¡é ¼åº¦: {final_stats['average_confidence']:.4f}")
            print("=" * 60)
    
    print("ğŸ¯ ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã—ã¾ã—ãŸ")
    print("ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print("  - screenshots/ : ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸç”»åƒ")
    print("  - detection_data/ : æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰")

# ===== ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ =====
if __name__ == "__main__":
    try:
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        for directory in ['screenshots', 'detection_data']:
            os.makedirs(directory, exist_ok=True)
        
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        
        if not MEDIAPIPE_AVAILABLE:
            print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: MediaPipeã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã¨æ‰‹èªè­˜æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã™")
            print("   ã‚³ãƒãƒ³ãƒ‰: pip install mediapipe")
            print("   è¨˜äº‹å‚è€ƒ: https://qiita.com/bianca26neve/items/...")
    finally:
        cv2.destroyAllWindows()
        print("ğŸ‘‹ ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†")
        print("\nğŸ™ å‚è€ƒã«ã—ãŸè¨˜äº‹:")
        print("ã€Mediapipeã§æ‰‹ã®å½¢çŠ¶æ¤œå‡ºã‚’è©¦ã—ã¦ã¿ãŸ(Python)ã€")
        print("by @bianca26neve on Qiita")
        print("MediaPipeã®ç´ æ™´ã‚‰ã—ã„æ©Ÿèƒ½ã‚’æ´»ç”¨ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸï¼")